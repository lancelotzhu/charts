1. You can check the status of HDFS by running this command:
   kubectl exec -n {{ .Release.Namespace }} -it {{ include "hadoop.fullname" . }}-hdfs-nn-0 -- /opt/hadoop/bin/hdfs dfsadmin -report

2. You can list the yarn nodes by running this command:
   kubectl exec -n {{ .Release.Namespace }} -it {{ include "hadoop.fullname" . }}-yarn-rm-0 -- /opt/hadoop/bin/yarn node -list

3. You can list ha status of  the name nodes by running this command:
   kubectl exec -n {{ .Release.Namespace }} -it {{ include "hadoop.fullname" . }}-hdfs-nn-0 -- /opt/hadoop/bin/hdfs haadmin -getAllServiceState

4. You can list ha status of  the resource managers by running this command:
   kubectl exec -n {{ .Release.Namespace }} -it {{ include "hadoop.fullname" . }}-hdfs-rm-0 -- /opt/hadoop/bin/yarn rmadmin -getAllServiceState

5. Create a port-forward to the yarn resource manager UI:
   kubectl port-forward -n {{ .Release.Namespace }} --address 127.0.0.1 service/{{ include "hadoop.fullname" . }}-yarn-rm 8088:8088

   Then open the ui in your browser:

   open http://localhost:8088

6. Create a port-forward to the name node UI:
   kubectl port-forward -n {{ .Release.Namespace }} --address 127.0.0.1 service/{{ include "hadoop.fullname" . }}-hdfs-nn 9870:9870

   Then open the ui in your browser:

   open http://localhost:9870

7. You can run included hadoop tests like this:
   kubectl exec -n {{ .Release.Namespace }} -it {{ include "hadoop.fullname" . }}-yarn-nm-0 -- /opt/hadoop/bin/hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-{{ .Values.hadoopVersion }}-tests.jar TestDFSIO -write -nrFiles 5 -fileSize 128MB -resFile /tmp/TestDFSIOwrite.txt

8. You can list the mapreduce jobs like this:
   kubectl exec -n {{ .Release.Namespace }} -it {{ include "hadoop.fullname" . }}-yarn-rm-0 -- /opt/hadoop/bin/mapred job -list

9. This chart can also be used with the zeppelin chart
    helm install --namespace {{ .Release.Namespace }} --set hadoop.useConfigMap=true,hadoop.configMapName={{ include "hadoop.fullname" . }} stable/zeppelin

10. You can scale the number of yarn nodes like this:
   helm upgrade {{ .Release.Name }} --set yarn.nodeManager.replicas=4 stable/hadoop

   Make sure to update the values.yaml if you want to make this permanent.
